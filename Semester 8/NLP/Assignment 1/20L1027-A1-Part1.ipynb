{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Assignment 1 - Natural Language Processing</center>\n",
    "#### **Name:** Fatima Azfar\n",
    "#### **Roll no:** 20L-1027\n",
    "#### **Section:** BDS-8A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Part 1: Regular Expressions and Preprocessing</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "Describe the class of strings matched by the following regular expressions.\n",
    "- [a-zA-Z]+\n",
    "- [A-Z][a-z]*\n",
    "- p[aeiou]{,2}t\n",
    "- \\d+(\\.\\d+)?\n",
    "- ([^aeiou][aeiou][^aeiou])*\n",
    "- \\w+|[^\\w\\s]+\n",
    "\n",
    "Test your answers using nltk.re_show(). (You will have to import libraries using “import nltk, re, pprint”)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, re, pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regular Expression: [a-zA-Z]+ -> One or more letters (uppercase or lowercase).\n",
      "Testing with string: 'Hello World!'\n",
      "{Hello} {World}!\n",
      "--------------------------------------------------------------------------------\n",
      "Regular Expression: [A-Z][a-z]* -> An uppercase letter followed by zero or more lowercase letters.\n",
      "Testing with string: 'Hello world'\n",
      "{Hello} world\n",
      "--------------------------------------------------------------------------------\n",
      "Regular Expression: p[aeiou]{,2}t -> A 'p' followed by at most two vowels and ending with 't'.\n",
      "Testing with string: 'pat, pet, peat, pt'\n",
      "{pat}, {pet}, {peat}, {pt}\n",
      "--------------------------------------------------------------------------------\n",
      "Regular Expression: \\d+(\\.\\d+)? -> An integer or a decimal number (with optional fractional part).\n",
      "Testing with string: '123, 4.56, .78'\n",
      "{123}, {4.56}, .{78}\n",
      "--------------------------------------------------------------------------------\n",
      "Regular Expression: ([^aeiou][aeiou][^aeiou])* -> Zero or more occurrences of a non-vowel, a vowel, and a non-vowel.\n",
      "Testing with string: 'bcdfghjklmnpqrstvwxyz'\n",
      "{}b{}c{}d{}f{}g{}h{}j{}k{}l{}m{}n{}p{}q{}r{}s{}t{}v{}w{}x{}y{}z{}\n",
      "--------------------------------------------------------------------------------\n",
      "Regular Expression: \\w+|[^\\w\\s]+ -> One or more word characters or one or more characters that are neither word characters nor whitespace.\n",
      "Testing with string: 'Hello, World!'\n",
      "{Hello}{,} {World}{!}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "regex_patterns = {\n",
    "    \"[a-zA-Z]+\": \"One or more letters (uppercase or lowercase).\",\n",
    "    \"[A-Z][a-z]*\": \"An uppercase letter followed by zero or more lowercase letters.\",\n",
    "    \"p[aeiou]{,2}t\": \"A 'p' followed by at most two vowels and ending with 't'.\",\n",
    "    \"\\\\d+(\\\\.\\\\d+)?\": \"An integer or a decimal number (with optional fractional part).\",\n",
    "    \"([^aeiou][aeiou][^aeiou])*\": \"Zero or more occurrences of a non-vowel, a vowel, and a non-vowel.\",\n",
    "    \"\\\\w+|[^\\w\\s]+\": \"One or more word characters or one or more characters that are neither word characters nor whitespace.\"\n",
    "}\n",
    "\n",
    "test_strings = {\n",
    "    \"[a-zA-Z]+\": \"Hello World!\",\n",
    "    \"[A-Z][a-z]*\": \"Hello world\",\n",
    "    \"p[aeiou]{,2}t\": \"pat, pet, peat, pt\",\n",
    "    \"\\\\d+(\\\\.\\\\d+)?\": \"123, 4.56, .78\",\n",
    "    \"([^aeiou][aeiou][^aeiou])*\": \"bcdfghjklmnpqrstvwxyz\",\n",
    "    \"\\\\w+|[^\\w\\s]+\": \"Hello, World!\"\n",
    "}\n",
    "\n",
    "def test_regex_patterns():\n",
    "    for pattern, description in regex_patterns.items():\n",
    "        print(f\"Regular Expression: {pattern} -> {description}\")\n",
    "        print(f\"Testing with string: '{test_strings[pattern]}'\")\n",
    "        nltk.re_show(pattern, test_strings[pattern])\n",
    "        print(\"-\"*80)\n",
    "\n",
    "test_regex_patterns()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "Write regular expressions to match the following classes of strings:\n",
    "\n",
    "- A single determiner (assume that a, an, and the are the only determiners).\n",
    "- An arithmetic expression using integers, addition, and multiplication, such as 2*3+8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regular Expression: \\b(a|an|the)\\b -> A single determiner.\n",
      "Testing with string: 'This is an apple. The apple is a fruit.'\n",
      "Matches found: ['an', 'The', 'a']\n",
      "--------------------------------------------------------------------------------\n",
      "Regular Expression: \\b\\d+\\s*[\\+\\*]\\s*\\d+\\s*[\\+\\*]\\s*\\d+\\b -> An arithmetic expression using integers, addition, and multiplication, such as 2*3+8.\n",
      "Testing with string: 'Here are two expressions: 2*3+8 and 3+5*9'\n",
      "Matches found: ['2*3+8', '3+5*9']\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "regex_patterns = {\n",
    "    r\"\\b(a|an|the)\\b\": \"A single determiner.\",\n",
    "    r\"\\b\\d+\\s*[\\+\\*]\\s*\\d+\\s*[\\+\\*]\\s*\\d+\\b\": \"An arithmetic expression using integers, addition, and multiplication, such as 2*3+8.\"\n",
    "}\n",
    "\n",
    "test_strings = {\n",
    "    r\"\\b(a|an|the)\\b\": \"This is an apple. The apple is a fruit.\",\n",
    "    r\"\\b\\d+\\s*[\\+\\*]\\s*\\d+\\s*[\\+\\*]\\s*\\d+\\b\": \"Here are two expressions: 2*3+8 and 3+5*9\",\n",
    "}\n",
    "\n",
    "def test_regex_patterns():\n",
    "    for pattern, description in regex_patterns.items():\n",
    "        print(f\"Regular Expression: {pattern} -> {description}\")\n",
    "        print(f\"Testing with string: '{test_strings[pattern]}'\")\n",
    "        print(\"Matches found:\", re.findall(pattern, test_strings[pattern], re.IGNORECASE))\n",
    "        print(\"-\"*80)\n",
    "\n",
    "test_regex_patterns()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Data Scraping</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "Write a utility function that takes a URL as its argument, and returns the contents of the URL, with all HTML markup removed. Use from urllib import request and then request urlopen(‘https://www.csail.mit.edu/people/’).read().decode('utf8') to access the contents of the URL. Use BeautifulSoup(html).get_text() to parse html.\n",
    "\n",
    "Import the following for this question:\n",
    "- from urllib import request\n",
    "- from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_from_url(url):\n",
    "    try:\n",
    "        response = request.urlopen(url)\n",
    "        html = response.read().decode('utf8')\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        text = soup.get_text()\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "People | MIT CSAIL\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    Skip to main content\n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "For Students\n",
      "\n",
      "\n",
      "For Industry\n",
      "\n",
      "\n",
      "For Members\n",
      "\n",
      "\n",
      "Accessibility\n",
      "\n",
      "\n",
      "Login\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "MIT CSAIL\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Research\n",
      "\n",
      "\n",
      "People\n",
      "\n",
      "\n",
      "News\n",
      "\n",
      "\n",
      "Events\n",
      "\n",
      "\n",
      "Symposia\n",
      "\n",
      "\n",
      "About\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "MIT LOGO\n",
      "Created with Sketch.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Research\n",
      "\n",
      "\n",
      "People\n",
      "\n",
      "\n",
      "News\n",
      "\n",
      "\n",
      "Events\n",
      "\n",
      "\n",
      "Symposia\n",
      "\n",
      "\n",
      "About\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "For Students\n",
      "\n",
      "\n",
      "For Industry\n",
      "\n",
      "\n",
      "For Members\n",
      "\n",
      "\n",
      "Accessibility\n",
      "\n",
      "\n",
      "Login\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Contact\n",
      "\n",
      "\n",
      "Press Requests\n",
      "\n",
      "\n",
      "Accessibility\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Search\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "MIT CSAIL\n",
      "\n",
      "\n",
      "Massachusetts Institute of Technology\n",
      "Computer Science & Artificial Intelligence Laboratory\n",
      "32 Vassar St, Cambridge MA 02139\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Contact\n",
      "\n",
      "\n",
      "Press Requests\n",
      "\n",
      "\n",
      "Accessibility\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.csail.mit.edu/people/'\n",
    "text = get_text_from_url(url)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Tokenization</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "Tokenize text parsed from the above url using nltk. Find all phone numbers and email addresses from this text using regular expressions. (Do not tokenize text otherwise email addresses will be incorrectly tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_contact_info(url):\n",
    "    text = get_text_from_url(url)\n",
    "    \n",
    "    phone_regex = r'(\\+\\d{1,2}\\s)?\\(?\\d{3}\\)?[\\s.-]\\d{3}[\\s.-]\\d{4}'\n",
    "    email_regex = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n",
    "    \n",
    "    phone_numbers = re.findall(phone_regex, text)\n",
    "    email_addresses = re.findall(email_regex, text)\n",
    "\n",
    "    return phone_numbers, email_addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------MIT-------\n",
      "Phone Numbers: []\n",
      "Email Addresses: []\n",
      "-------FAST NUCES-------\n",
      "Phone Numbers: []\n",
      "Email Addresses: ['admissions.lhr@nu.edu.pk', 'kashif.zafar@nu.edu.pk', 'aamir.wali@nu.edu.pk', 'asif.gilani@nu.edu.pk', 'hammad.naveed@nu.edu.pk', 'zareen.alamgir@nu.edu.pk', 'arshad.ali1@nu.edu.pk', 'asma.naseer@nu.edu.pk', 'irfan.younas@nu.edu.pk', 'r.asif@nu.edu.pk', 'saira.karim@nu.edu.pk', 'zeeshanali.khan@nu.edu.pk', 'aatira.anum@nu.edu.pk', 'ali.afzal@nu.edu.pk', 'ammar.haider@nu.edu.pk', 'asma.ahmad@nu.edu.pk', 'faisal.aslam@nu.edu.pk', 'farooq.ahmad@nu.edu.pk', 'hajra.waheed@nu.edu.pk', 'haroon.mahmood@nu.edu.pk', 'iqra.safder@nu.edu.pk', 'maryam.bashir@nu.edu.pk', 'mubasher.baig@nu.edu.pk', 'muhammad.ahmadraza@nu.edu.pk', 'm.Irteza@nu.edu.pk', 'tahir.ejaz@nu.edu.pk', 'zeeshan.rana@nu.edu.pk', 'aamir.raheem@nu.edu.pk', 'abeeda.akram@nu.edu.pk', 'ishaq.raza@nu.edu.pk', 'lehmia.kiran@nu.edu.pk', 'noshaba.nasir@nu.edu.pk', 'ali.omer@nu.edu.pk', 'samin.iftikhar@nu.edu.pk', 'sobia.tariq@nu.edu.pk', 'tahreem.yasir@nu.edu.pk', 'waqar.baig@nu.edu.pk', 'waqas.manzoor@nu.edu.pk', 'aleena.ahmad@nu.edu.pk', 'anosha.khan@nu.edu.pk', 'arooj.khalil@nu.edu.pk', 'asbah.khalid@lhr.nu.edu.pk', 'danyal.farhat@nu.edu.pk', 'fraz.yousaf@nu.edu.pk', 'usama.hassan@nu.edu.pk', 'hafsa.tariq@nu.edu.pk', 'hamad.ulqudous@nu.edu.pk', 'hina.iqbal@nu.edu.pk', 'hira.butt@nu.edu.pk', 'hira.ilyas@nu.edu.pk', 'muhammad.saif@nu.edu.pk', 'maham.naeem@nu.edu.pk', 'mamoona.majid@nu.edu.pk', 'mehroze.khan@nu.edu.pk', 'momna.zaneb@nu.edu.pk', 'mubashar.hussain@nu.edu.pk', 'muhammad.naveed@nu.edu.pk', 'saifullah.tanvir@nu.edu.pk', 'zeeshan.nazar@nu.edu.pk', 'namra.absar@nu.edu.pk', 'razi.uddin@nu.edu.pk', 'rubab.anam@nu.edu.pk', 'sana.fatima@nu.edu.pk', 'uzair.naqvi@nu.edu.pk', 'tayyaba.bukhari@nu.edu.pk', 'tazeem.haider@nu.edu.pk', 'umme.ammarah@nu.edu.pk', 'junaid.hussain@nu.edu.pk', 'usman.anwer@lhr.nu.edu.pk', 'seemab.ayub@nu.edu.pk', 'sohaib.ahmad@nu.edu.pk', 'sukhan.amir@nu.edu.pk', 'zehra.batool@nu.edu.pk', 'zoha.waheed@nu.edu.pk', 'mamoona.akbar@nu.edu.pk', 'nauman.moazzam@nu.edu.pk', 'salman.shoaib@nu.edu.pk', 'samman.ashraf@nu.edu.pk', 'saima.zafar@nu.edu.pk', 'sm.sajid@nu.edu.pk', 'aun.abbas@nu.edu.pk', 'omer.saleem@nu.edu.pk', 'jabran.khan@nu.edu.pk', 'kashif.saeed@nu.edu.pk', 'abdul.majid@nu.edu.pk', 'beenish.fatima@nu.edu.pk', 'bushra.rashid@nu.edu.pk', 'haris.kazmi@nu.edu.pk', 'kamran.jamal@nu.edu.pk', 'maimoona.akram@nu.edu.pk', 'mohsin.yousuf@nu.edu.pk', 'shazia.haque@nu.edu.pk', 'tamania.javaid@nu.edu.pk', 'akbari.yaqoob@nu.edu.pk', 'aroosa.umair@nu.edu.pk', 'hamza.yousuf@nu.edu.pk', 'samia.mahmood@nu.edu.pk', 'sara.kiran@nu.edu.pk', 'muhammad.ismail@nu.edu.pk', 'umer.altaf@nu.edu.pk', 'eisha.khan@nu.edu.pk', 'shahid.ali@nu.edu.pk', 'syed.ali@nu.edu.pk', 'Javaid.ahmad@nu.edu.pk', 'tauqir.ahmed@nu.edu.pk', 'waseem.mirza@nu.edu.pk', 'abdullah.rana@nu.edu.pk', 'm.umar@nu.edu.pk', 'aliraza.khalid@nu.edu.pk', 'sarah.asif@nu.edu.pk', 'umar.niazi@nu.edu.pk', 'anns.tahir@nu.edu.pk', 'asim.iqbal@nu.edu.pk', 'fahad.haseeb@nu.edu.pk', 'mahnoor.akram@nu.edu.pk', 'mubashir.islam@nu.edu.pk', 'shoaib.ameer@nu.edu.pk', 'hamza.ali@nu.edu.pk', 'maham.akram@nu.edu.pk', 'malieka.batool@nu.edu.pk', 'm.muneeb@nu.edu.pk', 'hamid.hassan@nu.edu.pk', 'akbar.azam@nu.edu.pk', 'ammar.javed@nu.edu.pk', 'amna.farrukh@nu.edu.pk', 'mujahid.hussain@nu.edu.pk', 'fatima.omer@nu.edu.pk', 'komal.kamran@nu.edu.pk', 'umer.iqbal@nu.edu.pk', 'zia.khan@nu.edu.pk', 'allauddin@gmail.com', 'shakeel.ahmad@nu.edu.pk', 'amina.tabassum@nu.edu.pk', 'aroosa.safdar@nu.edu.pk', 'ayesha.arshad@nu.edu.pk', 'beenish.arshad@nu.edu.pk', 'fatima.habib@nu.edu.pk', 'irma.tariq@nu.edu.pk', 'khadija.aslam@nu.edu.pk', 'noor.zahid@nu.edu.pk', 'salmaan.rahman@nu.edu.pk', 'sundas.munir@nu.edu.pk', 'ghulam.fatima@nu.edu.pk', 'iman.ilyas@nu.edu.pk', 'mubashir.qayyum@nu.edu.pk', 'sumaira.sarfraz@nu.edu.pk', 'akhlaq.ahmad@nu.edu.pk', 'mazhar.hussain@nu.edu.pk', 'saman.shahid@nu.edu.pk', 'farasat.shamir@nu.edu.pk', 'saeeda.zia@nu.edu.pk', 'hira.iqbal@nu.edu.pk', 'tahir.rashid@nu.edu.pk', 'tayyaba.naz@nu.edu.pk', 'waleed.shehzad@nu.edu.pk', 'zahida.mansoor@nu.edu.pk', 'hajra.ikram@nu.edu.pk', 'hina.firdous@nu.edu.pk', 'raheela.tariq@nu.edu.pk', 'ali.zulfiqar@nu.edu.pk', 'abdul.sattar@nu.edu.pk', 'aisha.bano@nu.edu.pk', 'ayesha.saeed@nu.edu.pk', 'hamza.janjua@nu.edu.pk', 'iqra.rafiq@nu.edu.pk', 'kanwal.saleem@nu.edu.pk', 'm.yaseen@nu.edu.pk', 'namra.fazal@nu.edu.pk', 'razm.zafar@nu.edu.pk', 'Sarah.ahmad@nu.edu.pk', 'tasduque.hussain@nu.edu.pk', 'mahnoor.chaudhary@nu.edu.pk', 'rida.ahmed@nu.edu.pk', 'aqsa.naz@nu.edu.pk', 'umair.gulzar@nu.edu.pk', 'nokhaiz.zahra@nu.edu.pk', 'rubab.arshad@nu.edu.pk']\n"
     ]
    }
   ],
   "source": [
    "# MIT Website\n",
    "url = 'https://www.csail.mit.edu/people/'\n",
    "phone_numbers, email_addresses = find_contact_info(url)\n",
    "print(\"-------MIT-------\")\n",
    "print(\"Phone Numbers:\", phone_numbers)\n",
    "print(\"Email Addresses:\", email_addresses)\n",
    "\n",
    "# FAST NU Website\n",
    "url = 'https://lhr.nu.edu.pk/faculty/'\n",
    "phone_numbers, email_addresses = find_contact_info(url)\n",
    "print(\"-------FAST NUCES-------\")\n",
    "print(\"Phone Numbers:\", phone_numbers)\n",
    "print(\"Email Addresses:\", email_addresses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The emails present on MIT's page were not fetched and parsed because of the dynamic objects within which the emails exist are present on the website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Stemming</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "Use the Porter Stemmer to normalize some tokenized text, calling the stemmer on each word. Do the same thing with the Lancaster Stemmer and see if you observe any differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer, LancasterStemmer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porter Stemmer: ['peopl', '|', 'mit', 'csail', 'skip', 'to', 'main', 'content', 'for', 'student', 'for', 'industri', 'for', 'member', 'access', 'login', 'mit', 'csail', 'research', 'peopl', 'new', 'event', 'symposia', 'about', 'mit', 'logo', 'creat', 'with', 'sketch', '.', 'research', 'peopl', 'new', 'event', 'symposia', 'about', 'for', 'student', 'for', 'industri', 'for', 'member', 'access', 'login', 'contact', 'press', 'request', 'access', 'search', 'mit', 'csail', 'massachusett', 'institut', 'of', 'technolog', 'comput', 'scienc', '&', 'artifici', 'intellig', 'laboratori', '32', 'vassar', 'st', ',', 'cambridg', 'ma', '02139', 'contact', 'press', 'request', 'access']\n",
      "Lancaster Stemmer: ['peopl', '|', 'mit', 'csail', 'skip', 'to', 'main', 'cont', 'for', 'stud', 'for', 'industry', 'for', 'memb', 'access', 'login', 'mit', 'csail', 'research', 'peopl', 'new', 'ev', 'sympos', 'about', 'mit', 'logo', 'cre', 'with', 'sketch', '.', 'research', 'peopl', 'new', 'ev', 'sympos', 'about', 'for', 'stud', 'for', 'industry', 'for', 'memb', 'access', 'login', 'contact', 'press', 'request', 'access', 'search', 'mit', 'csail', 'massachuset', 'institut', 'of', 'technolog', 'comput', 'sci', '&', 'art', 'intellig', 'lab', '32', 'vass', 'st', ',', 'cambridg', 'ma', '02139', 'contact', 'press', 'request', 'access']\n"
     ]
    }
   ],
   "source": [
    "tokens = word_tokenize(text)\n",
    "\n",
    "porter = PorterStemmer()\n",
    "lancaster = LancasterStemmer()\n",
    "\n",
    "# Porter Stemmer\n",
    "porter_stemmed = [porter.stem(token) for token in tokens]\n",
    "print(\"Porter Stemmer:\", porter_stemmed)\n",
    "\n",
    "# Stemmer\n",
    "lancaster_stemmed = [lancaster.stem(token) for token in tokens]\n",
    "print(\"Lancaster Stemmer:\", lancaster_stemmed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "For this question, assume you have a shy friend who is hesitating to tell you something, so he/ she sent a long random text on WhatsApp that also contains his/ her message. Since you are a Regex Guru, your task is to extract the actual message from the random text using regular expressions and some rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = \"Pila Forfeited you engrossed but 1kometimes explained. Another 1kacokaco1 as studied it to evident. Merry sense 9given he be arisepila. Conduct at an replied removal an amongst. Remainingzalima 0determine few her two cordially Zalima admitting old. Sometimes ctra*nger his pisdsdla ourselves her co*la depending you boy. Eat discretion cultivated possession far comparison projection pila considered. And few fat interested discovered inquietude insensible unsatiable increasing zalima eat.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Word: Zalima, Frequency: 2\n",
      "Second Word: coka\n",
      "Third Word: cola\n",
      "Fourth Word: Pila, Frequency: 2\n",
      "Third Word: de\n",
      "The hidden sentence is:  Zalima coka cola Pila de\n"
     ]
    }
   ],
   "source": [
    "patterns = {\n",
    "    'first_word': r'\\b[Zz][a-z]*a\\b',\n",
    "    'second_word': r'\\b\\d[k][a-z]*\\d\\b',\n",
    "    'third_word': r'\\bc[a-z]*\\*[a-z]+a\\b',\n",
    "    'fourth_word': r'\\b[Pp][a-z]{2}a\\b'\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for key, pattern in patterns.items():\n",
    "    matches = re.findall(pattern, message)\n",
    "    results[key] = matches\n",
    "\n",
    "# First word\n",
    "first_word = results['first_word'][0] if results['first_word'] else None\n",
    "first_word_count = len(results['first_word'])\n",
    "\n",
    "# Second word\n",
    "second_word_raw = results['second_word'][0] if results['second_word'] else None\n",
    "second_word = second_word_raw[3:-3] if second_word_raw else None\n",
    "\n",
    "# Third word\n",
    "third_word_raw = results['third_word'][0] if results['third_word'] else None\n",
    "third_word = third_word_raw.replace('*', '') if third_word_raw else None\n",
    "\n",
    "# Fourth word\n",
    "fourth_word = results['fourth_word'][0] if results['fourth_word'] else None\n",
    "fourth_word_count = len(results['fourth_word'])\n",
    "\n",
    "# Fifth word\n",
    "fifth_word = \"de\"\n",
    "\n",
    "print(f\"First Word: {first_word}, Frequency: {first_word_count}\")\n",
    "print(f\"Second Word: {second_word}\")\n",
    "print(f\"Third Word: {third_word}\")\n",
    "print(f\"Fourth Word: {fourth_word}, Frequency: {fourth_word_count}\")\n",
    "print(f\"Third Word: {fifth_word}\")\n",
    "print(\"The hidden sentence is: \",first_word +\" \"+ second_word +\" \"+ third_word +\" \"+ fourth_word +\" \"+ fifth_word)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
